{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Address - Run twice! Multithreading\n",
    "Match addresses witouth a parent. Perhaps there is a sibling in the same year inside?\n",
    "The magic! Here we match addresses. You can run this file on an external server - it will take some times.  \n",
    "**You have to run this twice, for hcp and hco's! Change the variable `run_for`**\n",
    "\n",
    "**Info next time: Try to set condition_address to 0 on HCO. To many not found pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import sys\n",
    "import os.path\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for = 'hco'\n",
    "version = 0.5\n",
    "num_process = mp.cpu_count() * 2\n",
    "\n",
    "# Conditions\n",
    "conditions = {\n",
    "    'hcp' :\n",
    "        {\n",
    "            'condition_location': 85,\n",
    "            'condition_address': 0,\n",
    "            'condition_name': 89\n",
    "        },\n",
    "    'hco' :\n",
    "        {\n",
    "            'condition_location': 85,\n",
    "            'condition_address': 0,\n",
    "            'condition_name': 85\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check path\n",
    "Check, if we run in in the git directory or on the server. If on a server, look for the files in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Server or Git\n",
    "path_git = '../../data/3. transformation/5_%s_matched_forced.csv'\n",
    "path_server = '5_%s_matched_forced.csv'\n",
    "\n",
    "on_git = os.path.isfile(path_git % run_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if on_git:\n",
    "    df = pd.read_csv(path_git % run_for)\n",
    "else:\n",
    "    df = pd.read_csv(path_server % run_for)\n",
    "\n",
    "df_data = df[df.type == run_for].copy()\n",
    "df_data['address'] = df_data['address'].fillna(\"\")\n",
    "\n",
    "#For Testing\n",
    "#df_data = df_data[df_data.source.isin(['eli', 'shire', 'almirall'])]\n",
    "\n",
    "total_rows = len(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Start fuzzy matcher THREADS hco 0.5\n",
      "Cores detected: 4\n",
      "Threads started: 8\n",
      "Rows to match: 4575\n",
      "Start time: 2020-08-17 22:01:55.410538\n",
      "===============================\n",
      "Thread started\n",
      "Thread started\n",
      "Thread started\n",
      "Thread started\n",
      "Thread started\n",
      "Thread started\n",
      "Thread Data len: 88\n",
      "Thread Data len: 88\n",
      "Thread Data len: 88\n",
      "Thread Data len: 88\n",
      "Thread Data len: 88\n",
      "Thread Data len: 88\n",
      "Thread Data len: 88\n",
      "Thread Data len: 84\n",
      "Total len: 700\n",
      "\n",
      "Thread started\n",
      "Thread started\n",
      "Progress: 90.91%\n",
      "len ds_matchlist_new 1690\n",
      "\n",
      "Finished in: 0.66 minutes\n"
     ]
    }
   ],
   "source": [
    "#Convert\n",
    "df_data['name_expand'] = df_data['name_expand'].astype(\"str\")\n",
    "df_data['address_expand'] = df_data['address_expand'].astype(\"str\")\n",
    "df_data['location_expand'] = df_data['location_expand'].astype(\"str\")\n",
    "\n",
    "#Sort\n",
    "df_data = df_data.sort_values('name_expand')\n",
    "\n",
    "cond = conditions[run_for]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"===============================\")\n",
    "print(\"Start fuzzy matcher THREADS %s %s\" % (run_for, version))\n",
    "print(\"Cores detected: %s\" % mp.cpu_count())\n",
    "print(\"Threads started: %s\" % num_process)\n",
    "print(\"Rows to match: %s\" % total_rows)\n",
    "print(\"Start time: %s\" % datetime.datetime.now())\n",
    "print(\"===============================\")\n",
    "\n",
    "def run(datasets):\n",
    "    print(\"Thread started\")\n",
    "    df_data = datasets['df_data']\n",
    "    df_part = datasets['df_part']\n",
    "    \n",
    "    #create empty matchlist\n",
    "    df_matchlist = pd.DataFrame(columns=['source', 'target', 'r_name', 'r_address', 'r_location', 'r_ratio'])\n",
    "    \n",
    "    counter = 0\n",
    "    total_rows = len(df_part)\n",
    "    for index, row in df_part.iterrows():\n",
    "\n",
    "        #Frist Fuzzynize only location\n",
    "        df_data['r_location'] = 0\n",
    "        df_data['r_address'] = 0\n",
    "        df_data['r_name'] = 0\n",
    "\n",
    "        df_data['r_location'] = df_data['location_expand'].apply(lambda x: fuzz.token_set_ratio(x, row['location_expand']))\n",
    "\n",
    "        #Fuzzy name, when r_location >= 85\n",
    "        df_data['r_name'] = df_data.loc[df_data.r_location >= cond['condition_location'], 'name_expand'].apply(lambda x: fuzz.token_set_ratio(x.lower(), row['name_expand']))\n",
    "\n",
    "        #Fuzzy address, when r_location > 85 & r_name >= 80\n",
    "        df_data['r_address'] = df_data.loc[(df_data.r_location >= cond['condition_location']) & (df_data.r_name >= cond['condition_name']), 'address_expand'].apply(lambda x: np.amax([fuzz.token_set_ratio(x, row['address_expand']), fuzz.partial_ratio(x, row['address_expand'])]))\n",
    "\n",
    "        condition_fix = (df_data.index != index)\n",
    "        if row['address'] == '':\n",
    "            condition1 = (df_data.r_name >= cond['condition_name']) & (df_data.r_location >= cond['condition_location']) & (condition_fix)\n",
    "        else:\n",
    "            condition1 = (df_data.r_name >= cond['condition_name']) & (df_data.r_location >= cond['condition_location']) & (df_data.r_address >= cond['condition_address']) & (condition_fix)\n",
    "\n",
    "        #Select by condition\n",
    "        df_matches = df_data[(condition1)]\n",
    "\n",
    "        #Matchlist Add to matchlist\n",
    "        if len(df_matches) > 0:\n",
    "            for match_index, match_row in df_matches.iterrows():\n",
    "\n",
    "                df_matchlist = df_matchlist.append({'source': row['internalid'], \n",
    "                                                    'target': match_row['internalid'],\n",
    "                                                    'r_name': match_row['r_name'],\n",
    "                                                    'r_address': match_row['r_address'],\n",
    "                                                    'r_location': match_row['r_location'],\n",
    "                                                   }, ignore_index=True)\n",
    "\n",
    "\n",
    "        if counter % 10 == 0:\n",
    "            sys.stdout.write(\"\\rProgress: %s%%\" % round(100 / total_rows * counter, 2))\n",
    "            sys.stdout.flush()\n",
    "                \n",
    "        counter += 1\n",
    "\n",
    "    return df_matchlist\n",
    "    \n",
    "\n",
    "#Create pool\n",
    "pool = mp.Pool(processes = num_process)\n",
    "\n",
    "#Create Jobs\n",
    "jobs = []\n",
    "df_selection = df_data[df_data.parent == -1]\n",
    "job_len = int(math.ceil(len(df_selection) / num_process))\n",
    "for x in range(0, num_process):\n",
    "    part = df_selection[x * job_len : x * job_len + job_len]\n",
    "    jobs.append({\"df_data\": df_data.copy(), \"df_part\": part})\n",
    "    print('Thread Data len: ' + str(len(part)))\n",
    "\n",
    "    \n",
    "print(\"Total len: \" + str(len(df_selection)))\n",
    "print(\"\")\n",
    "\n",
    "#Run Threats \n",
    "matchlist_list = pool.map(run, jobs)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "#Concat Results\n",
    "ds_matchlist_new = pd.concat(matchlist_list)\n",
    "print(\"\")\n",
    "print(\"len ds_matchlist_new \" + str(len(ds_matchlist_new)))\n",
    "\n",
    "#Time Spend\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinished in: ' + str(round(elapsed_time / 60, 2)) + ' minutes')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if on_git:\n",
    "    #df_data.to_csv('../../data/3. transformation/5_%s_matches_final.csv' % run_for, index=False)\n",
    "    ds_matchlist_new.to_csv('../../data/3. transformation/6_%s_matchlist.csv' % run_for, index=False)\n",
    "else:\n",
    "    #df_data.to_csv('5_%s_matches_final.csv' % run_for, index=False)\n",
    "    ds_matchlist_new.to_csv('6_%s_matchlist.csv' % run_for, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
