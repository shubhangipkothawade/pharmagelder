{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Database Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '../../data/lib/')\n",
    "from consts import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../../data/3. transformation/7_hcp_grouped_final.csv', dtype = dataframe_types)\n",
    "df1 = pd.read_csv('../../data/3. transformation/7_hco_grouped_final.csv', dtype = dataframe_types)\n",
    "df_accumulation_raw = pd.read_csv('../../data/3. transformation/1_accumulations_all.csv', dtype = dataframe_types)\n",
    "\n",
    "df_pharma = pd.read_csv('sources/liste_companies.csv')\n",
    "df_pharma_source_raw = pd.read_csv('sources/pharma_source.csv')\n",
    "plz_names = ['REC_ART', 'ONRP', 'BFSNR', 'PLZ_TYP', 'POSTLEITZAHL', 'PLZ_ZZ', 'GPLZ', 'ORTBEZ18', \n",
    "             'ORTBEZ27', 'KANTON', 'SPRACHCODE', 'SPRACHCODE_ABW', 'BRIEFZ_DURCH', 'GILT_AB_DAT', 'PLZ_BRIEFZUST', 'PLZ_COFF']\n",
    "df_plz_raw = pd.read_csv('sources/Post_Adressdaten20190122_edited.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Group Key\n",
    "HCO and HCP both have same indexes. Generate unique values for the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcp = df0.copy()\n",
    "df_hco = df1.copy()\n",
    "\n",
    "group_key = 1\n",
    "\n",
    "def set_groupkey(dataframe, startkey):\n",
    "    for g in dataframe['group'].unique():\n",
    "        dataframe.loc[dataframe['group'] == g, 'group_key'] = startkey\n",
    "        startkey += 1\n",
    "        #print(g)\n",
    "\n",
    "    dataframe.drop(axis=1, columns=['group'])\n",
    "    return (dataframe, startkey)\n",
    "\n",
    "df_hcp, group_key = set_groupkey(df_hcp, group_key)\n",
    "df_hco, group_key = set_groupkey(df_hco, group_key)\n",
    "\n",
    "#Concat\n",
    "df_data = pd.concat([df_hcp, df_hco], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean\n",
    "df_data.drop(axis=1, columns=['group'], inplace=True)\n",
    "\n",
    "#Format\n",
    "df_data['group_key'] = df_data['group_key'].astype('int')\n",
    "\n",
    "#Reindex\n",
    "df_data.reset_index(drop=True, inplace=True)\n",
    "df_data.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `transaction_category`\n",
    "Create this table by hand. IDs have to be this way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = [\n",
    "    {\n",
    "        'trc_id': 1,\n",
    "        'trc_name': 'donations_grants'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 2,\n",
    "        'trc_name': 'sponsorship'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 3,\n",
    "        'trc_name': 'registration_fees'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 4,\n",
    "        'trc_name': 'travel_accommodation'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 5,\n",
    "        'trc_name': 'fees'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 6,\n",
    "        'trc_name': 'related_expenses'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 7,\n",
    "        'trc_name': 'rnd'\n",
    "    }\n",
    "]\n",
    "\n",
    "df_transaction_category =  pd.DataFrame(category_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `transaction`\n",
    "\n",
    "If you have conversion errors, your data is not clean eq there are strings in value fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "\n",
    "def add_transaction(df_new, row, column, cat_id):\n",
    "    if not np.isnan(row[column]) and (row[column] != 0):\n",
    "        global c\n",
    "        c += 1\n",
    "        \n",
    "        df_new = df_new.append({\n",
    "          'tra_id': 0,\n",
    "          'tra_fk_pharma': row['pha_id'],\n",
    "          'tra_fk_recipient': row['group_key'],\n",
    "          'tra_year': row['year'],\n",
    "          'tra_fk_transaction_category': cat_id,\n",
    "          'tra_value': row[column],\n",
    "          'tra_name_original': row['name'],\n",
    "          'tra_location_original': row['location'], \n",
    "          'tra_address_original': row['address']\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return df_new\n",
    "\n",
    "#Create empty dataframe\n",
    "col_names =  [\n",
    "              'tra_id', \n",
    "              'tra_fk_pharma',\n",
    "              'tra_fk_recipient',\n",
    "              'tra_year',\n",
    "              'tra_fk_transaction_category',\n",
    "              'tra_value',\n",
    "              'tra_name_original',\n",
    "              'tra_location_original', \n",
    "              'tra_address_original'\n",
    "            ]\n",
    "\n",
    "df_transaction  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "#Copy dataframe\n",
    "df_data_temp = df_data.copy()\n",
    "\n",
    "#Join with pharma\n",
    "df_data_temp = df_data_temp.merge(right = df_pharma, how='left', left_on='source', right_on='pha_key')\n",
    "\n",
    "#Prepare transaction category id\n",
    "cat_donations_grants = df_transaction_category.loc[df_transaction_category.trc_name == 'donations_grants', 'trc_id'].iloc[0]\n",
    "cat_sponsorship = df_transaction_category.loc[df_transaction_category.trc_name == 'sponsorship', 'trc_id'].iloc[0]\n",
    "cat_registration_fees = df_transaction_category.loc[df_transaction_category.trc_name == 'registration_fees', 'trc_id'].iloc[0]\n",
    "cat_travel_accommodation = df_transaction_category.loc[df_transaction_category.trc_name == 'travel_accommodation', 'trc_id'].iloc[0]\n",
    "cat_fees = df_transaction_category.loc[df_transaction_category.trc_name == 'fees', 'trc_id'].iloc[0]\n",
    "cat_related_expenses = df_transaction_category.loc[df_transaction_category.trc_name == 'related_expenses', 'trc_id'].iloc[0]\n",
    "\n",
    "#Iter Addresses\n",
    "for index, row in df_data_temp.iterrows():\n",
    "    df_transaction = add_transaction(df_transaction, row, 'donations_grants', cat_donations_grants)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'sponsorship', cat_sponsorship)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'registration_fees', cat_registration_fees)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'travel_accommodation', cat_travel_accommodation)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'fees', cat_fees)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'related_expenses', cat_related_expenses)\n",
    "\n",
    "#Set tra_id to index + 1\n",
    "df_transaction['tra_id'] = df_transaction.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `recipient`\n",
    "Import PLZ and create `zip_shadow` with all possible Zips for this location.  \n",
    "Source: https://www.post.ch/de/geschaeftlich/themen-a-z/adressen-pflegen-und-geodaten-nutzen/adress-und-geodaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>address</th>\n",
       "      <th>plz</th>\n",
       "      <th>uci</th>\n",
       "      <th>donations_grants</th>\n",
       "      <th>sponsorship</th>\n",
       "      <th>registration_fees</th>\n",
       "      <th>travel_accommodation</th>\n",
       "      <th>fees</th>\n",
       "      <th>related_expenses</th>\n",
       "      <th>total</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>main_address</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a Elisabet Safwan Andreani</td>\n",
       "      <td>Bellinzona</td>\n",
       "      <td>CH</td>\n",
       "      <td>Viale Stazione 30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>446.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>742.00</td>\n",
       "      <td>hcp</td>\n",
       "      <td>novo</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Brand</td>\n",
       "      <td>Münchenbuchsee</td>\n",
       "      <td>CH</td>\n",
       "      <td>Oberdortstrasse 25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>hcp</td>\n",
       "      <td>daiichi</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Delabays</td>\n",
       "      <td>Morges</td>\n",
       "      <td>CH</td>\n",
       "      <td>Chemin du Crêt 2</td>\n",
       "      <td>1110</td>\n",
       "      <td>40747652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1485.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1919.00</td>\n",
       "      <td>hcp</td>\n",
       "      <td>daiichi</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Delabays</td>\n",
       "      <td>Dübendorf</td>\n",
       "      <td>CH</td>\n",
       "      <td>Praxis Dr. Basic Adila, Bettlistrasse 35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.83</td>\n",
       "      <td>hcp</td>\n",
       "      <td>vifor</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A. Gerber</td>\n",
       "      <td>Zürich</td>\n",
       "      <td>CH</td>\n",
       "      <td>Witellikerstrasse 36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>607.00</td>\n",
       "      <td>hcp</td>\n",
       "      <td>daiichi</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name        location country  \\\n",
       "group_key                                                       \n",
       "1          a Elisabet Safwan Andreani      Bellinzona      CH   \n",
       "2                            A. Brand  Münchenbuchsee      CH   \n",
       "3                         A. Delabays          Morges      CH   \n",
       "4                         A. Delabays       Dübendorf      CH   \n",
       "5                           A. Gerber          Zürich      CH   \n",
       "\n",
       "                                            address   plz       uci  \\\n",
       "group_key                                                             \n",
       "1                                 Viale Stazione 30   NaN       NaN   \n",
       "2                                Oberdortstrasse 25   NaN       NaN   \n",
       "3                                  Chemin du Crêt 2  1110  40747652   \n",
       "4          Praxis Dr. Basic Adila, Bettlistrasse 35   NaN       NaN   \n",
       "5                              Witellikerstrasse 36   NaN       NaN   \n",
       "\n",
       "           donations_grants  sponsorship  registration_fees  \\\n",
       "group_key                                                     \n",
       "1                       0.0          0.0              296.0   \n",
       "2                       0.0          0.0              160.0   \n",
       "3                       0.0          0.0              434.0   \n",
       "4                       0.0          0.0                0.0   \n",
       "5                       0.0          0.0              607.0   \n",
       "\n",
       "           travel_accommodation  fees  related_expenses    total type  \\\n",
       "group_key                                                               \n",
       "1                        446.00   0.0               0.0   742.00  hcp   \n",
       "2                          0.00   0.0               0.0   160.00  hcp   \n",
       "3                       1485.00   0.0               0.0  1919.00  hcp   \n",
       "4                        295.83   0.0               0.0   295.83  hcp   \n",
       "5                          0.00   0.0               0.0   607.00  hcp   \n",
       "\n",
       "            source  year  main_address  \n",
       "group_key                               \n",
       "1             novo  2015           1.0  \n",
       "2          daiichi  2015           1.0  \n",
       "3          daiichi  2015           1.0  \n",
       "4            vifor  2015           1.0  \n",
       "5          daiichi  2015           1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check: Are there any groups without main_address\n",
    "df_recipient = df_data.copy()\n",
    "gr = df_recipient.groupby('group_key').first()\n",
    "gr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_recipient = df_data.copy()\n",
    "df_plz = df_plz_raw.copy()\n",
    "\n",
    "#Only main_address\n",
    "df_recipient.sort_values(by='main_address', inplace=True)\n",
    "df_recipient = df_recipient.groupby('group_key').first()\n",
    "\n",
    "#Remove year\n",
    "#df_recipient.drop(columns='_export_information', axis=1, inplace=True)\n",
    "df_recipient.drop(columns=['year', 'address_expand', 'location_expand', 'name_expand'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "#Group PLZ by location\n",
    "df_plz['plz_shadow'] = df_plz['POSTLEITZAHL'].astype('str')\n",
    "df_plz['ORTBEZ18'] = df_plz['ORTBEZ18'].str.lower()\n",
    "df_plz = df_plz.groupby('ORTBEZ18')['plz_shadow'].agg(lambda col: ','.join(col))\n",
    "df_plz = df_plz.to_frame()\n",
    "\n",
    "#abstract index\n",
    "df_recipient['id'] = df_recipient.index\n",
    "#df_recipient['id'] = df_recipient['group_key']\n",
    "\n",
    "#Lowercase location\n",
    "df_recipient['location_lower'] = df_recipient['location'].str.lower()\n",
    "\n",
    "#Join recipient and zip\n",
    "df_recipient = df_recipient.merge(right = df_plz, how='left', left_on='location_lower', right_on='ORTBEZ18')\n",
    "\n",
    "#covert plz\n",
    "df_recipient['plz'] = df_recipient['plz'].astype('int', errors='ignore')\n",
    "\n",
    "#Drop\n",
    "df_recipient.drop(axis=1, columns=['location_lower', 'main_address', 'donations_grants', 'sponsorship', 'registration_fees', 'travel_accommodation', 'fees', 'related_expenses', 'total', 'source'], inplace=True)\n",
    "\n",
    "#Add rec_zero_money = 0\n",
    "df_recipient['rec_zero_money'] = 0\n",
    "\n",
    "#Add rec_visible = true\n",
    "df_recipient['rec_visible'] = 1\n",
    "\n",
    "#rename\n",
    "df_recipient.columns = [\n",
    "        'rec_name',\n",
    "        'rec_location',\n",
    "        'rec_country',\n",
    "        'rec_address',\n",
    "        'rec_plz',\n",
    "        'rec_uci',\n",
    "        'rec_type',\n",
    "        'rec_id',\n",
    "        'rec_plz_shadow',\n",
    "        'rec_zero_money',\n",
    "        'rec_visible'\n",
    "    ]\n",
    "\n",
    "#Reorder Columns\n",
    "df_recipient = df_recipient[[\n",
    "        'rec_id',\n",
    "        'rec_name',\n",
    "        'rec_address',\n",
    "        'rec_location',\n",
    "        'rec_plz',\n",
    "        'rec_plz_shadow',\n",
    "        'rec_country',\n",
    "        'rec_uci',\n",
    "        'rec_zero_money',\n",
    "        'rec_visible',\n",
    "        'rec_type'\n",
    "    ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `accumulations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_accumulation(df_new, row, column):\n",
    "    if not np.isnan(row[column]) and (row[column] != 0):\n",
    "        \n",
    "        category = df_transaction_category.loc[df_transaction_category.trc_name == column, 'trc_id']\n",
    "        df_new = df_new.append({\n",
    "          'acc_id': 0,\n",
    "          'acc_fk_pharma': row['pha_id'],\n",
    "          'acc_year': row['year'],\n",
    "          'acc_fk_transaction_category': category.iloc[0],\n",
    "          'acc_value': row[column],\n",
    "          'acc_type': row['type'],\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return df_new\n",
    "\n",
    "#Create empty dataframe\n",
    "col_names =  [\n",
    "              'acc_id', \n",
    "              'acc_fk_pharma',\n",
    "              'acc_year',\n",
    "              'acc_fk_transaction_category',\n",
    "              'acc_value',\n",
    "              'acc_type'\n",
    "            ]\n",
    "\n",
    "df_accumulation_new  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "#Copy dataframe\n",
    "df_accumulation = df_accumulation_raw.copy()\n",
    "\n",
    "#Select amounts (no counts)\n",
    "df_accumulation = df_accumulation[df_accumulation['type'].isin(['hcp_amount', 'hco_amount', 'rnd'])]\n",
    "\n",
    "#Rename hcp_acount & hco_acmount\n",
    "df_accumulation['type'] = df_accumulation['type'].str.replace('_amount', '')\n",
    "\n",
    "#Join with pharma\n",
    "df_accumulation = df_accumulation.merge(right = df_pharma, how='left', left_on='source', right_on='pha_key')\n",
    "\n",
    "#Iter Accumulations\n",
    "for index, row in df_accumulation.iterrows():\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'donations_grants')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'sponsorship')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'registration_fees')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'travel_accommodation')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'fees')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'related_expenses')\n",
    "    \n",
    "\n",
    "#Add RnD\n",
    "for index, row in df_accumulation[df_accumulation.type == 'rnd'].iterrows():\n",
    "    if not np.isnan(row['total']) and (row['total'] != 0):\n",
    "        category = df_transaction_category.loc[df_transaction_category.trc_name == 'rnd', 'trc_id']\n",
    "        df_accumulation_new = df_accumulation_new.append({\n",
    "          'acc_id': 0,\n",
    "          'acc_fk_pharma': row['pha_id'],\n",
    "          'acc_year': row['year'],\n",
    "          'acc_fk_transaction_category': category.iloc[0],\n",
    "          'acc_value': row['total'],\n",
    "          'acc_type': row['type'],\n",
    "        }, ignore_index=True)\n",
    "\n",
    "#Set acc_id to index + 1\n",
    "df_accumulation_new['acc_id'] = df_accumulation_new.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `pharma_source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharma_source = df_pharma_source_raw.copy()\n",
    "\n",
    "#Join with pharma\n",
    "df_pharma_source = df_pharma_source.merge(right = df_pharma, how='left', left_on='phs_key', right_on='pha_key')\n",
    "\n",
    "#drop columns\n",
    "df_pharma_source.drop(columns=['pha_name', 'pha_key', 'phs_key', 'pha_name'], inplace=True)\n",
    "\n",
    "#abstract index\n",
    "df_pharma_source.index += 1\n",
    "df_pharma_source.reset_index(drop=False, inplace=True)\n",
    "\n",
    "#Rename\n",
    "df_pharma_source.columns = [\n",
    "    'phs_id',\n",
    "    'phs_source',\n",
    "    'phs_fk_pharma'\n",
    "]\n",
    "\n",
    "#Reorder\n",
    "df_pharma_source = df_pharma_source[[\n",
    "    'phs_id',\n",
    "    'phs_fk_pharma',\n",
    "    'phs_source'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `pharma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharma.drop(axis=1, columns=['pha_key'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction_category.to_csv('../../data/4. database/0_transaction_category.csv', index=False)\n",
    "df_pharma.to_csv('../../data/4. database/1_pharma.csv', index=False)\n",
    "df_pharma_source.to_csv('../../data/4. database/2_pharma_source.csv', index=False)\n",
    "df_recipient.to_csv('../../data/4. database/3_recipient.csv', index=False)\n",
    "df_transaction.to_csv('../../data/4. database/4_transaction.csv', index=False)\n",
    "df_accumulation_new.to_csv('../../data/4. database/5_accumulation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Files\n",
    "```sql\n",
    "DELETE FROM accumulation WHERE acc_id > 0;\n",
    "DELETE FROM pharma_source WHERE phs_id > 0;\n",
    "DELETE FROM pharma WHERE pha_id > 0;\n",
    "DELETE FROM recipient WHERE rec_id > 0;\n",
    "DELETE FROM transaction WHERE tra_id > 0;\n",
    "DELETE FROM transaction_category WHERE trc_id > 0;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def export_sql(df, tablename, path):\n",
    "    #Columns\n",
    "    columns = list(map(lambda x: \"`\" + x + \"`\", df.columns))\n",
    "    columns = ', '.join(columns)\n",
    "\n",
    "    #Values\n",
    "    df = df.fillna(\"\")\n",
    "    rows = []\n",
    "    #qry\n",
    "    for row in df.values:\n",
    "        row_s = list(map(lambda x: \"'\" + str(x).replace(\"'\", \"\\\\'\") + \"'\", row))\n",
    "        row_s = '\\n(' +  ', '.join(row_s) + ')'\n",
    "        rows.append(row_s)\n",
    "\n",
    "    sublists  = list(chunks(rows, 3000))\n",
    "    inserts = []\n",
    "    for sub in sublists:\n",
    "        inserts.append('INSERT INTO %s (%s) VALUES %s;' % (tablename, columns, ', '.join(sub)))\n",
    "        \n",
    "    all_inserts = '\\n'.join(inserts)\n",
    "\n",
    "    #Safe File\n",
    "    text_file = open(path, \"w\")\n",
    "    text_file.write(\"START TRANSACTION;\\n%s\\nCOMMIT;\\n\" % all_inserts)\n",
    "    text_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_sql(df_transaction_category, 'transaction_category', '../../data/4. database/0_transaction_category.sql')\n",
    "export_sql(df_pharma, 'pharma', '../../data/4. database/1_pharma.sql')\n",
    "export_sql(df_pharma_source, 'pharma_source', '../../data/4. database/2_pharma_source.sql')\n",
    "export_sql(df_recipient, 'recipient', '../../data/4. database/3_recipient.sql')\n",
    "export_sql(df_transaction, 'transaction', '../../data/4. database/4_transaction.sql')\n",
    "export_sql(df_accumulation_new, 'accumulation', '../../data/4. database/5_accumulation.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat files\n",
    "filenames = ['../../data/4. database/0_transaction_category.sql',\n",
    "             '../../data/4. database/1_pharma.sql',\n",
    "             '../../data/4. database/2_pharma_source.sql',\n",
    "             '../../data/4. database/3_recipient.sql',\n",
    "             '../../data/4. database/4_transaction.sql',\n",
    "             '../../data/4. database/5_accumulation.sql'\n",
    "             ]\n",
    "with open('../../data/4. database/data_dump.sql', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
