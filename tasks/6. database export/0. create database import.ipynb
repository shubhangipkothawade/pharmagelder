{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Database Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '../../data/lib/')\n",
    "from consts import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../../data/3. transformation/6_hcp_grouped.csv', dtype = dataframe_types)\n",
    "df1 = pd.read_csv('../../data/3. transformation/6_hco_grouped.csv', dtype = dataframe_types)\n",
    "df_accumulation_raw = pd.read_csv('../../data/3. transformation/1_accumulations_all.csv', dtype = dataframe_types)\n",
    "\n",
    "df_pharma = pd.read_csv('sources/liste_companies.csv')\n",
    "df_pharma_source_raw = pd.read_csv('sources/pharma_source.csv')\n",
    "plz_names = ['REC_ART', 'ONRP', 'BFSNR', 'PLZ_TYP', 'POSTLEITZAHL', 'PLZ_ZZ', 'GPLZ', 'ORTBEZ18', \n",
    "             'ORTBEZ27', 'KANTON', 'SPRACHCODE', 'SPRACHCODE_ABW', 'BRIEFZ_DURCH', 'GILT_AB_DAT', 'PLZ_BRIEFZUST', 'PLZ_COFF']\n",
    "df_plz_raw = pd.read_csv('sources/Post_Adressdaten20190122_edited.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Group Key\n",
    "HCO and HCP both have same indexes. Generate unique values for the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcp = df0.copy()\n",
    "df_hco = df1.copy()\n",
    "\n",
    "group_key = 1\n",
    "\n",
    "def set_groupkey(dataframe, startkey):\n",
    "    for g in dataframe['group'].unique():\n",
    "        dataframe.loc[dataframe['group'] == g, 'group_key'] = startkey\n",
    "        startkey += 1\n",
    "        #print(g)\n",
    "\n",
    "    dataframe.drop(axis=1, columns=['group'])\n",
    "    return (dataframe, startkey)\n",
    "\n",
    "df_hcp, group_key = set_groupkey(df_hcp, group_key)\n",
    "df_hco, group_key = set_groupkey(df_hco, group_key)\n",
    "\n",
    "#Concat\n",
    "df_data = pd.concat([df_hcp, df_hco], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean\n",
    "df_data.drop(axis=1, columns=['group'], inplace=True)\n",
    "\n",
    "#Format\n",
    "df_data['group_key'] = df_data['group_key'].astype('int')\n",
    "\n",
    "#Reindex\n",
    "df_data.reset_index(drop=True, inplace=True)\n",
    "df_data.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `transaction_category`\n",
    "Create this table by hand. IDs have to be this way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = [\n",
    "    {\n",
    "        'trc_id': 1,\n",
    "        'trc_name': 'donations_grants'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 2,\n",
    "        'trc_name': 'sponsorship'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 3,\n",
    "        'trc_name': 'registration_fees'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 4,\n",
    "        'trc_name': 'travel_accommodation'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 5,\n",
    "        'trc_name': 'fees'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 6,\n",
    "        'trc_name': 'related_expenses'\n",
    "    },\n",
    "    {\n",
    "        'trc_id': 7,\n",
    "        'trc_name': 'total'\n",
    "    }\n",
    "]\n",
    "\n",
    "df_transaction_category =  pd.DataFrame(category_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `transaction`\n",
    "\n",
    "If you have conversion errors, your data is not clean eq there are strings in value fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30630\n",
      "44504\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "\n",
    "def add_transaction(df_new, row, column, cat_id):\n",
    "    if not np.isnan(row[column]) and (row[column] != 0):\n",
    "        global c\n",
    "        c += 1\n",
    "        \n",
    "        df_new = df_new.append({\n",
    "          'tra_id': 0,\n",
    "          'tra_fk_pharma': row['pha_id'],\n",
    "          'tra_fk_recipient': row['group_key'],\n",
    "          'tra_year': row['year'],\n",
    "          'tra_fk_transaction_category': cat_id,\n",
    "          'tra_value': row[column],\n",
    "          'tra_name_original': row['name'],\n",
    "          'tra_location_original': row['location'], \n",
    "          'tra_address_original': row['address']\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return df_new\n",
    "\n",
    "#Create empty dataframe\n",
    "col_names =  [\n",
    "              'tra_id', \n",
    "              'tra_fk_pharma',\n",
    "              'tra_fk_recipient',\n",
    "              'tra_year',\n",
    "              'tra_fk_transaction_category',\n",
    "              'tra_value',\n",
    "              'tra_name_original',\n",
    "              'tra_location_original', \n",
    "              'tra_address_original'\n",
    "            ]\n",
    "\n",
    "df_transaction  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "#Copy dataframe\n",
    "df_data_temp = df_data.copy()\n",
    "\n",
    "#TEMP!!!!\n",
    "#df_data_temp = df_data[0:10].copy()\n",
    "print(len(df_data_temp))\n",
    "\n",
    "#Join with pharma\n",
    "df_data_temp = df_data_temp.merge(right = df_pharma, how='left', left_on='source', right_on='pha_key')\n",
    "\n",
    "#Prepare transaction category id\n",
    "cat_donations_grants = df_transaction_category.loc[df_transaction_category.trc_name == 'donations_grants', 'trc_id'].iloc[0]\n",
    "cat_sponsorship = df_transaction_category.loc[df_transaction_category.trc_name == 'sponsorship', 'trc_id'].iloc[0]\n",
    "cat_registration_fees = df_transaction_category.loc[df_transaction_category.trc_name == 'registration_fees', 'trc_id'].iloc[0]\n",
    "cat_travel_accommodation = df_transaction_category.loc[df_transaction_category.trc_name == 'travel_accommodation', 'trc_id'].iloc[0]\n",
    "cat_fees = df_transaction_category.loc[df_transaction_category.trc_name == 'fees', 'trc_id'].iloc[0]\n",
    "cat_related_expenses = df_transaction_category.loc[df_transaction_category.trc_name == 'related_expenses', 'trc_id'].iloc[0]\n",
    "\n",
    "#Iter Addresses\n",
    "for index, row in df_data_temp.iterrows():\n",
    "    df_transaction = add_transaction(df_transaction, row, 'donations_grants', cat_donations_grants)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'sponsorship', cat_sponsorship)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'registration_fees', cat_registration_fees)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'travel_accommodation', cat_travel_accommodation)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'fees', cat_fees)\n",
    "    df_transaction = add_transaction(df_transaction, row, 'related_expenses', cat_related_expenses)\n",
    "\n",
    "#Set tra_id to index + 1\n",
    "df_transaction['tra_id'] = df_transaction.index + 1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `recipient`\n",
    "Import PLZ and create `zip_shadow` with all possible Zips for this location.  \n",
    "Source: https://www.post.ch/de/geschaeftlich/themen-a-z/adressen-pflegen-und-geodaten-nutzen/adress-und-geodaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_recipient = df_data.copy()\n",
    "df_plz = df_plz_raw.copy()\n",
    "\n",
    "#Only main_address\n",
    "df_recipient = df_recipient[df_recipient.main_address == 1]\n",
    "\n",
    "#Remove year\n",
    "#df_recipient.drop(columns='_export_information', axis=1, inplace=True)\n",
    "df_recipient.drop(columns=['year', 'address_expand', 'location_expand', 'name_expand'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "#Group PLZ by location\n",
    "df_plz['plz_shadow'] = df_plz['POSTLEITZAHL'].astype('str')\n",
    "df_plz['ORTBEZ18'] = df_plz['ORTBEZ18'].str.lower()\n",
    "df_plz = df_plz.groupby('ORTBEZ18')['plz_shadow'].agg(lambda col: ','.join(col))\n",
    "df_plz = df_plz.to_frame()\n",
    "\n",
    "#abstract index\n",
    "df_recipient['id'] = df_recipient['group_key']\n",
    "\n",
    "#Lowercase location\n",
    "df_recipient['location_lower'] = df_recipient['location'].str.lower()\n",
    "\n",
    "#Join recipient and zip\n",
    "df_recipient = df_recipient.merge(right = df_plz, how='left', left_on='location_lower', right_on='ORTBEZ18')\n",
    "\n",
    "#covert plz\n",
    "df_recipient['plz'] = df_recipient['plz'].astype('int', errors='ignore')\n",
    "\n",
    "#Drop\n",
    "df_recipient.drop(axis=1, columns=['group_key', 'location_lower', 'main_address', 'donations_grants', 'sponsorship', 'registration_fees', 'travel_accommodation', 'fees', 'related_expenses', 'total', 'source'], inplace=True)\n",
    "\n",
    "#Add rec_zero_money = 0\n",
    "df_recipient['rec_zero_money'] = 0\n",
    "\n",
    "\n",
    "#rename\n",
    "df_recipient.columns = [\n",
    "        'rec_name',\n",
    "        'rec_location',\n",
    "        'rec_country',\n",
    "        'rec_address',\n",
    "        'rec_plz',\n",
    "        'rec_uci',\n",
    "        'rec_type',\n",
    "        'rec_id',\n",
    "        'rec_plz_shadow',\n",
    "        'rec_zero_money'\n",
    "    ]\n",
    "\n",
    "#Reorder Columns\n",
    "df_recipient = df_recipient[[\n",
    "        'rec_id',\n",
    "        'rec_name',\n",
    "        'rec_address',\n",
    "        'rec_location',\n",
    "        'rec_plz',\n",
    "        'rec_plz_shadow',\n",
    "        'rec_country',\n",
    "        'rec_uci',\n",
    "        'rec_zero_money',\n",
    "        'rec_type'\n",
    "    ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `accumulations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_accumulation(df_new, row, column):\n",
    "    if not np.isnan(row[column]) and (row[column] != 0):\n",
    "        \n",
    "        category = df_transaction_category.loc[df_transaction_category.trc_name == column, 'trc_id']\n",
    "        df_new = df_new.append({\n",
    "          'acc_id': 0,\n",
    "          'acc_fk_pharma': row['pha_id'],\n",
    "          'acc_year': row['year'],\n",
    "          'acc_fk_transaction_category': category.iloc[0],\n",
    "          'acc_value': row[column],\n",
    "          'acc_type': row['type'],\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return df_new\n",
    "\n",
    "#Create empty dataframe\n",
    "col_names =  [\n",
    "              'acc_id', \n",
    "              'acc_fk_pharma',\n",
    "              'acc_year',\n",
    "              'acc_fk_transaction_category',\n",
    "              'acc_value',\n",
    "              'acc_type'\n",
    "            ]\n",
    "\n",
    "df_accumulation_new  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "#Copy dataframe\n",
    "df_accumulation = df_accumulation_raw.copy()\n",
    "\n",
    "#Convert floats\n",
    "\"\"\"\n",
    "df_accumulation = convert_float(df_accumulation, 'donations_grants')\n",
    "df_accumulation = convert_float(df_accumulation, 'sponsorship')\n",
    "df_accumulation = convert_float(df_accumulation, 'registration_fees')\n",
    "df_accumulation = convert_float(df_accumulation, 'travel_accommodation')\n",
    "df_accumulation = convert_float(df_accumulation, 'fees')\n",
    "df_accumulation = convert_float(df_accumulation, 'related_expenses')\n",
    "df_accumulation = convert_float(df_accumulation, 'total')\n",
    "\"\"\"\n",
    "\n",
    "#Select amounts (no counts)\n",
    "df_accumulation = df_accumulation[df_accumulation['type'].isin(['hcp_amount', 'hco_amount', 'rnd'])]\n",
    "\n",
    "#Rename hcp_acount & hco_acmount\n",
    "df_accumulation['type'] = df_accumulation['type'].str.replace('_amount', '')\n",
    "\n",
    "#Join with pharma\n",
    "df_accumulation = df_accumulation.merge(right = df_pharma, how='left', left_on='source', right_on='pha_key')\n",
    "\n",
    "#Iter Accumulations\n",
    "for index, row in df_accumulation.iterrows():\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'donations_grants')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'sponsorship')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'registration_fees')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'travel_accommodation')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'fees')\n",
    "    df_accumulation_new = add_accumulation(df_accumulation_new, row, 'related_expenses')\n",
    "    \n",
    "\n",
    "#Add RnD\n",
    "for index, row in df_accumulation[df_accumulation.type == 'rnd'].iterrows():\n",
    "    if not np.isnan(row['total']) and (row['total'] != 0):\n",
    "        category = df_transaction_category.loc[df_transaction_category.trc_name == 'total', 'trc_id']\n",
    "        df_accumulation_new = df_accumulation_new.append({\n",
    "          'acc_id': 0,\n",
    "          'acc_fk_pharma': row['pha_id'],\n",
    "          'acc_year': row['year'],\n",
    "          'acc_fk_transaction_category': category.iloc[0],\n",
    "          'acc_value': row['total'],\n",
    "          'acc_type': row['type'],\n",
    "        }, ignore_index=True)\n",
    "\n",
    "#Set acc_id to index + 1\n",
    "df_accumulation_new['acc_id'] = df_accumulation_new.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `pharma_source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharma_source = df_pharma_source_raw.copy()\n",
    "\n",
    "#Join with pharma\n",
    "df_pharma_source = df_pharma_source.merge(right = df_pharma, how='left', left_on='phs_key', right_on='pha_key')\n",
    "\n",
    "#drop columns\n",
    "df_pharma_source.drop(columns=['pha_name', 'pha_key', 'phs_key', 'pha_name'], inplace=True)\n",
    "\n",
    "#abstract index\n",
    "df_pharma_source.index += 1\n",
    "df_pharma_source.reset_index(drop=False, inplace=True)\n",
    "\n",
    "#Rename\n",
    "df_pharma_source.columns = [\n",
    "    'phs_id',\n",
    "    'phs_source',\n",
    "    'phs_fk_pharma'\n",
    "]\n",
    "\n",
    "#Reorder\n",
    "df_pharma_source = df_pharma_source[[\n",
    "    'phs_id',\n",
    "    'phs_fk_pharma',\n",
    "    'phs_source'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table `pharma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharma.drop(axis=1, columns=['pha_key'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction_category.to_csv('../../data/4. database/0_transaction_category.csv', index=False)\n",
    "df_pharma.to_csv('../../data/4. database/1_pharma.csv', index=False)\n",
    "df_pharma_source.to_csv('../../data/4. database/2_pharma_source.csv', index=False)\n",
    "df_recipient.to_csv('../../data/4. database/3_recipient.csv', index=False)\n",
    "df_transaction.to_csv('../../data/4. database/4_transaction.csv', index=False)\n",
    "df_accumulation_new.to_csv('../../data/4. database/5_accumulation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Files\n",
    "```sql\n",
    "DELETE FROM accumulation WHERE acc_id > 0;\n",
    "DELETE FROM pharma_source WHERE phs_id > 0;\n",
    "DELETE FROM pharma WHERE pha_id > 0;\n",
    "DELETE FROM recipient WHERE rec_id > 0;\n",
    "DELETE FROM transaction WHERE tra_id > 0;\n",
    "DELETE FROM transaction_category WHERE trc_id > 0;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def export_sql(df, tablename, path):\n",
    "    #Columns\n",
    "    columns = list(map(lambda x: \"`\" + x + \"`\", df.columns))\n",
    "    columns = ', '.join(columns)\n",
    "\n",
    "    #Values\n",
    "    df = df.fillna(\"\")\n",
    "    rows = []\n",
    "    #qry\n",
    "    for row in df.values:\n",
    "        row_s = list(map(lambda x: \"'\" + str(x).replace(\"'\", \"\\\\'\") + \"'\", row))\n",
    "        row_s = '\\n(' +  ', '.join(row_s) + ')'\n",
    "        rows.append(row_s)\n",
    "\n",
    "    sublists  = list(chunks(rows, 3000))\n",
    "    inserts = []\n",
    "    for sub in sublists:\n",
    "        inserts.append('INSERT INTO %s (%s) VALUES %s;' % (tablename, columns, ', '.join(sub)))\n",
    "        \n",
    "    all_inserts = '\\n'.join(inserts)\n",
    "\n",
    "    #Safe File\n",
    "    text_file = open(path, \"w\")\n",
    "    text_file.write(\"START TRANSACTION;\\n%s\\nCOMMIT;\\n\" % all_inserts)\n",
    "    text_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_sql(df_transaction_category, 'transaction_category', '../../data/4. database/0_transaction_category.sql')\n",
    "export_sql(df_pharma, 'pharma', '../../data/4. database/1_pharma.sql')\n",
    "export_sql(df_pharma_source, 'pharma_source', '../../data/4. database/2_pharma_source.sql')\n",
    "export_sql(df_recipient, 'recipient', '../../data/4. database/3_recipient.sql')\n",
    "export_sql(df_transaction, 'transaction', '../../data/4. database/4_transaction.sql')\n",
    "export_sql(df_accumulation_new, 'accumulation', '../../data/4. database/5_accumulation.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat files\n",
    "filenames = ['../../data/4. database/0_transaction_category.sql',\n",
    "             '../../data/4. database/1_pharma.sql',\n",
    "             '../../data/4. database/2_pharma_source.sql',\n",
    "             '../../data/4. database/3_recipient.sql',\n",
    "             '../../data/4. database/4_transaction.sql',\n",
    "             '../../data/4. database/5_accumulation.sql'\n",
    "             ]\n",
    "with open('../../data/4. database/data_dump.sql', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
